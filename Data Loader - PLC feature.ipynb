{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def x(X):\n",
    "    sample = np.random.random([512])\n",
    "    sampleX = np.stack([sample[x:x+24] for x in range(511-24)])\n",
    "    sampleY = np.stack([sample[x+24] for x in range(511-24)])\n",
    "    np.linalg.pinv((sampleX.T @ sampleX)) @ sampleX.T @ sampleY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as sio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"./datasets/clarin-long/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fnames_from_clarin_corpus(ROOT):\n",
    "    rec_fnames, trans_fnames = [], []\n",
    "    for i in [x for x in os.listdir(ROOT) if os.path.isdir(os.path.join(ROOT, x))]:\n",
    "        recordings = os.path.join(ROOT, i, \"wav\")\n",
    "        transcripts = os.path.join(ROOT, i, \"lab\")\n",
    "        for fname in os.listdir(recordings):\n",
    "            core, extension = fname.split(\".\")\n",
    "            assert extension == \"wav\"\n",
    "            if os.path.isfile(os.path.join(transcripts, core + \".hlb\")):\n",
    "                rec_fnames.append(os.path.join(recordings, fname))\n",
    "                trans_fnames.append(os.path.join(transcripts, core + \".hlb\"))\n",
    "    return rec_fnames, trans_fnames\n",
    "\n",
    "rec_fnames, trans_fnames = get_fnames_from_clarin_corpus(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recording_lengths(fnames):\n",
    "    lens = []\n",
    "    for f in fnames:\n",
    "        sr, data = sio.read(f)\n",
    "        assert sr == 16000\n",
    "        assert len(data.shape) == 1\n",
    "        lens.append(len(data))\n",
    "    return lens\n",
    "\n",
    "lens = get_recording_lengths(rec_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_lens = np.array(sorted(lens))\n",
    "step = len(sorted_lens) // 10\n",
    "delimiter_lens = [sorted_lens[step * i] for i in range(10)]\n",
    "delimiters = [step * i for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter_lens.append(sorted_lens[-1] + 128)\n",
    "indices = []\n",
    "for i in range(10):\n",
    "    lb, hb = delimiter_lens[i], delimiter_lens[i+1]\n",
    "    indices.append((lb <= np.array(lens)) * (np.array(lens) < hb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64269,\n",
       " 141920,\n",
       " 166560,\n",
       " 186240,\n",
       " 205120,\n",
       " 223520,\n",
       " 243600,\n",
       " 266000,\n",
       " 293600,\n",
       " 338880,\n",
       " 1585088]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delimiter_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phones_clarin(fname):\n",
    "    with open(fname, \"r\", encoding=\"utf-8\") as f:\n",
    "        s = f.read()\n",
    "        s = s.split(\"Phoneme Phoneme\")[1]\n",
    "        s = s.split(\"\\n\\n\")[0]\n",
    "        s = [x.split(' ')[1] for x in s.split('\\n') if x.strip()]\n",
    "        s = [x.split('_')[0] for x in s]\n",
    "    return s\n",
    "\n",
    "transes = (get_phones_clarin(x) for x in trans_fnames)\n",
    "all_phones = set()\n",
    "\n",
    "def len_add_set(trans):\n",
    "    global all_phones\n",
    "    all_phones |= set(trans)\n",
    "    return len(trans)\n",
    "\n",
    "trans_lens = [len_add_set(x) for x in transes]\n",
    "list(all_phones), max(trans_lens), len(list(all_phones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "NFEAT = 24\n",
    "\n",
    "phone_dict = list(all_phones)\n",
    "phone_zero = len(phone_dict)\n",
    "\n",
    "def reg(X):\n",
    "    sample = np.random.random([512])\n",
    "    sampleX = np.stack([sample[x:x+NFEAT] for x in range(511-NFEAT)])\n",
    "    sampleY = np.stack([sample[x+NFEAT] for x in range(511-NFEAT)])\n",
    "    return np.linalg.pinv((sampleX.T @ sampleX)) @ sampleX.T @ sampleY\n",
    "\n",
    "def callback(data):\n",
    "    length = 1 + (len(data) - 512) // 128\n",
    "    rec = np.zeros([length, NFEAT])\n",
    "    for i in range(length):\n",
    "        subbin = data[i * 128 : 128 * i + 512]\n",
    "        rec[i, :NFEAT] = reg(subbin)\n",
    "    return rec\n",
    "\n",
    "# callback = lambda x: np.log(np.abs(librosa.stft(x, n_fft=512, hop_length=128).T) ** 2) + 2e-12)\n",
    "# callback = lambda x: librosa.feature.mfcc(S=librosa.feature.melspectrogram(x, sr=16000, n_fft=512, hop_length=128), sr=16000).T\n",
    "\n",
    "# N_SIZE = 1\n",
    "# BIN_SIZE = 257\n",
    "# BIN_SIZE = 20\n",
    "LENGTHS = [1 + (len(x) - 512) // 128 for x in delimiter_lens[1:]]\n",
    "\n",
    "for ix, stratum in enumerate(indices):\n",
    "    ixes = np.where(stratum)[0]\n",
    "    shape = [len(ixes), LENGTHS[ix] + 4, NFEAT]\n",
    "    print(shape)\n",
    "    phones_shape = [len(ixes), max([trans_lens[x] for x in ixes]) + 1]\n",
    "    specs, transes = None, None\n",
    "    specs = np.zeros(shape, np.float32)\n",
    "    transes = np.ones(phones_shape, np.uint16) * phone_zero\n",
    "    for num, rec_ix in enumerate(ixes):\n",
    "        print(num)\n",
    "        fname = rec_fnames[rec_ix]\n",
    "        data = sio.read(fname)[1].astype(np.float32) / 2**15\n",
    "        stft = callback(data)\n",
    "        # print(stft.shape, specs.shape)\n",
    "        specs[num, :stft.shape[0], :NFEAT] = stft\n",
    "        trans = get_phones_clarin(trans_fnames[rec_ix])\n",
    "        trans = np.array([phone_dict.index(x) for x in trans])\n",
    "        transes[num, :len(trans)] = trans\n",
    "    np.save(os.path.join(ROOT, \"clarin-mfcc-rec-aligned-PLC-{}\".format(ix)), specs)\n",
    "    np.save(os.path.join(ROOT, \"clarin-mfcc-trans-aligned-PLC-{}\".format(ix)), transes)\n",
    "    print(\"Saved batch\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "librosa.feature.mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.feature.mfcc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.random.normal(size=[32000,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.feature.mfcc(time, sr=16000).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.stft(time, n_fft=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.feature.mfcc(S=librosa.feature.melspectrogram(time, sr=16000, n_fft=512, hop_length=128), sr=16000).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/pictec/datasets/clarin-long/data/SES0001/lab/sent001.plb\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
