{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In speech processing we may use really huge networks cause majority of the processing bottleneck is on CPU and running the CTC function...\n",
    "\n",
    "Also, CLARIN mobile corpus seems to be too small for advanced network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5523 5536\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "# For demonstration purposes - Pawe≈Ç Tomasik\n",
    "\n",
    "# for CLARIN_MOBILE - generally it is unnormalized\n",
    "\n",
    "class TrainingGenerator:\n",
    "    \"\"\"\n",
    "    Loads data in batches. It has well defined shape of an array into which load. At the beginning of training,\n",
    "    loads new ordering of samples that are in multiple files. Using memmap, load the selected data into the back buffer.\n",
    "    Self.ordering\n",
    "    \n",
    "    Switches between two banks, using one bank while filling the other in the background thread.\n",
    "    ...    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_files, Y_files, buffer_limit_size=4*(2**30), batch_size):\n",
    "        \"\"\"Assuming that X_files and Y_files are corresponding\"\"\"\n",
    "        self.front_buffer = None\n",
    "        self.back_buffer = None\n",
    "        self.X_files = X_files\n",
    "        self.Y_files = Y_files\n",
    "        samples, times = [], []\n",
    "        for file in X_files:\n",
    "            data = np.load(file, mmap_mode='r')\n",
    "            n_sample, time, fftwidth = data.shape\n",
    "            dtype = data.dtype\n",
    "            samples.append(n_sample)\n",
    "            times.append(time)\n",
    "        rec_time = max(times)\n",
    "        self.samples_per_file = samples\n",
    "        size_of_recording = 4 * times * fftwidth\n",
    "        self.n_records_in_buffer = buffer_limit_size // size_of_recording\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_slider = 0\n",
    "        # initialize the front buffer, run the back buffer\n",
    "                \n",
    "    def new_epoch(self):\n",
    "        permutations = np.stack([\n",
    "            np.stack([np.ones(samples) * recording, np.arange(samples)]).T\n",
    "            for recording, samples in self.samples_per_file\n",
    "        ], axis=0)\n",
    "        self.permutation = np.random.permute(permutations)\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.buffer_slider + self.batch_size < self.n_records_in_buffer:\n",
    "            returnable = self.front_buffer[self.buffer_slider : self.buffer_slider + self.batch_size]\n",
    "            self.buffer_slider += self.batch_size\n",
    "            return returnable\n",
    "        else:\n",
    "            \"\"\"\n",
    "            Create the return buffer\n",
    "            Fill first recordings from the old front buffer\n",
    "            Switch buffers, trigger the buffer replacement\n",
    "            Get the last recordings from the beginning of the new buffer\n",
    "            Return the buffer\n",
    "            \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack([np.ones(10), np.arange(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9828605914302957"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_lens >= Y_lens).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_lens == 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
